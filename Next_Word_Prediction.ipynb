{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Word Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8gH88QbNe8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from pickle import dump,load\n",
        "from google.colab import files\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TaaQHnmNr_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()  #upload your moby.txt file here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT0IhgBON7kr",
        "colab_type": "code",
        "outputId": "944fe83e-5a20-4bb5-b1f9-3f19d3364fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('moby.txt') as f:\n",
        "  txt = f.read()\n",
        "\n",
        "print(\"Text Length : \",len(txt))\n",
        "\n",
        "nlp = spacy.load('en', disable = ['parser','tagger','ner'])\n",
        "nlp.max_length = len(txt)*2\n",
        "\n",
        "tokens = [token.text.lower() for token in nlp(txt) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()-.*+,~/:;<=>?@[\\\\]^_`{|}\\t\\n ']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Length :  1232923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePsnqCB9RqtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(0,len(tokens) -25 -1):\n",
        "  x.append(tokens[i:i+25])\n",
        "  y.append(tokens[i+25:i+26])\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x)\n",
        "\n",
        "x = tokenizer.texts_to_sequences(x)\n",
        "y = tokenizer.texts_to_sequences(y)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "y = to_categorical(y, num_classes = len(tokenizer.word_counts) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcha14pGbM9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(len(tokenizer.word_counts)+1, 25, input_length = 25))\n",
        "model.add(LSTM(50, return_sequences = True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dense(len(tokenizer.word_counts)+1, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kF3nj4xeTJj",
        "colab_type": "code",
        "outputId": "da77e9b9-e6ba-48e3-f211-8c98fee45b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 25)            452225    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 25, 50)            15200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18089)             922539    \n",
            "=================================================================\n",
            "Total params: 1,412,714\n",
            "Trainable params: 1,412,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U--V1b5hekBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x,y, batch_size = 256, epochs = 350, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKM7ZYPtnocG",
        "colab_type": "code",
        "outputId": "8da8846d-a28d-401d-9b13-2d1a4b7f9f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dct = list(tokenizer.word_index.keys())\n",
        "\n",
        "for i in range(14,50):\n",
        "  pred = np.reshape(x[i], (1,25))\n",
        "  print(dct[model.predict_classes(pred)[0]], end = ' ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a to a aye number as electronic is unharming was to included files fail keeping laws expatiate they check it these of water with to in employed of reported empire that hunters volition slaves encourage will "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgNBACi1n8Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxs1AsaS6B18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('300.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsy0LO8OFu6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(tokenizer,open('tokenizer','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS3Ld2AvVqKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}